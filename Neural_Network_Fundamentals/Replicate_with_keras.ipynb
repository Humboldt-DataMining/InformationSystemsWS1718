{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Keras\n",
    "\n",
    "We are now going to reimplement the previous neural network with the Keras framework. Keras is an open source neural network library written in Python. It has the advantage of abstracting most of the boiler-plate code one needs to write when implementing a neural net only with a linear algebra library. Thus, it is suitable to fast prototyping and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important you make sure you have the required libraries installed for it to work. We will make use of three main libraries and their dependencies, which will be automatically installed.\n",
    "\n",
    "If you are using Anconda's Python distribution, we advise you to run `conda install keras pandas numpy` on the terminal. Otherwise, using the `pip` package manager should also do the trick. Run `pip install keras pandas numpy` on the terminal.\n",
    "\n",
    "The version of Python that will be used throughout this notebook is Python 3.6.4 from Anaconda's distribution. You can check your version of Python by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.3 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "To load the data, we will use the very handy `panda`'s `read_csv` function. It frees us from the burden of parsing the text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  1  2  3  4  5  6  7  8  9 ...   775  776  777  778  779  780  781  782  \\\n",
       "0  7  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0    0    0   \n",
       "1  2  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0    0    0   \n",
       "2  1  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0    0    0   \n",
       "4  4  0  0  0  0  0  0  0  0  0 ...     0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  784  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"y\"] + list(range(1,785))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/mnist_train.csv\", \n",
    "                 names=names)\n",
    "\n",
    "df_test = pd.read_csv(\"data/mnist_test.csv\", \n",
    "                     names=names)\n",
    "\n",
    "\n",
    "# df.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we separate labels from features in both train and test set and transform them from dataframes to numpy arrays, which are better suited for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 0, 4, ..., 5, 6, 8]),\n",
       " array([7, 2, 1, ..., 4, 5, 6]),\n",
       " array([[ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        ..., \n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01]]),\n",
       " array([[ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        ..., \n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01],\n",
       "        [ 0.01,  0.01,  0.01, ...,  0.01,  0.01,  0.01]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df['y'].values\n",
    "X_train = df.iloc[:, 1:].values/255*0.99+0.01\n",
    "\n",
    "y_test = df_test['y'].values\n",
    "X_test = df_test.iloc[:, 1:].values/255*0.99+0.01\n",
    "\n",
    "[y_train, y_test, X_train, X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if the shape of the arrays correspond to the expected. In fact, the shape is correct. We have 60 thousand observations in the train set and 10 thousand in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60000,), (60000, 784), (10000,), (10000, 784)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_train.shape, X_train.shape, y_test.shape, X_test.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining the model, one extra step is necessary: transform the labels so they are one-hot encoded. One-hot encoding a vector means transforming it into a matrix of ones and zeroes only with as many columns as the number of different values in the vector. In the specific case, the label vector becomes a ten-column array, each column representing one digit. If the label of the observation is 2, it will have zeroes in columns expect in the third column, which will have a one. The number of rows remains the same. with the same number of rows as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000, 10), (60000, 10)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "[y_test.shape, y_train.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train*0.99+0.01\n",
    "# y_test = y_test*0.99+0.01\n",
    "\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Define the model\n",
    "We finally come to the most important part. We will accomplish the task of building the neural network with only eight lines of code.\n",
    "\n",
    "The model in question consits of one input, one hidden and one ouput layer. The activation function of the hidden layer is a ReLU. And we use as the optimizer Stochastic Gradient Descent. \n",
    "\n",
    "Keras makes it very simple to add new layers. One needs only to call the `add` method on the model and pass the layer with its specfications. As you can see, the number of inputs needs to be specified only in the first layer. Keras inferes the input number of a layer by looking at the number of outputs of its predecessor.\n",
    "\n",
    "For this neural network, we will only use dense layers, which are layers with all nodes fully connected to each other. Keras, however, allows you to arbitrally build your neural networks by providing different types of layers, such as convolutional and pooling layers.\n",
    "\n",
    "You can learn more about differnt types of activation functions and optimizers using the following links:\n",
    "- https://keras.io/optimizers/\n",
    "- https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(num_hidden_n, num_pixels, num_classes, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_hidden_n, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "Having definied the structure of the model, we can now instantiate a concrete version of it by picking the relevant parameters and calling the function that returns the model object.\n",
    "\n",
    "Here we have chosen the hidden layers to have 90 nodes, while input and output layers have 784 and 10 nodes respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pixels, num_hidden_n, num_classes = 784, 90, 10\n",
    "optimizer = 'sgd'\n",
    "\n",
    "model = baseline_model(num_hidden_n, num_pixels, num_classes, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model\n",
    "With the model instantiated, we can finally call the fit method on it using the data set we prepared before.\n",
    "\n",
    "After training the model we evaluate its perfmoance by looking at its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 2s - loss: 1.9537 - acc: 0.5054\n",
      "Epoch 2/5\n",
      " - 2s - loss: 1.1453 - acc: 0.7680\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.7509 - acc: 0.8296\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.5942 - acc: 0.8552\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.5129 - acc: 0.8706\n",
      "Baseline Error: 11.96%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=200,\n",
    "          verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 11.96%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Error rate: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate does not seem very good. Maybe we could try a different optimizer. We will instantiate and fit the model again with the RMSprop optimization algorithm. By using Keras, the only thing you need to do is to pass a different argument to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 2s - loss: 0.4963 - acc: 0.8723\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.2401 - acc: 0.9306\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.1828 - acc: 0.9477\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.1466 - acc: 0.9581\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.1223 - acc: 0.9640\n",
      "Baseline Error: 3.54%\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model(num_hidden_n,\n",
    "                       num_pixels,\n",
    "                       num_classes,\n",
    "                       optimizer = \"rmsprop\")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=200,\n",
    "          verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "Once trained, you might want to use the model in the future. You can do so by saving it to a file for later use. Keras comes equipped with the `save` method, which allows you to easily save your trained model to the disk.\n",
    "\n",
    "We are going to save the model into a file called `model.h5` and delete it from memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the model from the file we just created and evaluate it again to make sure that during the saving process, the model hasn't been corrupted. The base line error is the same: the model has been successfully saved and can be shared with third-parties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 3.54%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model2 = load_model(\"model.h5\")\n",
    "\n",
    "scores2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores2[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
