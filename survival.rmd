---
title: "Survival Analysis"
output: html_notebook
---

```{r include = FALSE}
if(!require("survival")) install.packages("survival"); library("survival")
if(!require("survminer")) install.packages("survminer"); library("survminer")
if(!require("ggplot2")) install.packages("ggplot2"); library("ggplot2")
if(!require("ggfortify")) install.packages("ggfortify"); library("ggfortify")
if(!require("survAUC")) install.packages("survAUC"); library("survAUC")
if(!require("pec")) install.packages("pec"); library("pec")
if(!require("timereg")) install.packages("timereg"); library("timereg")
if(!require("KMsurv")) install.packages("KMsurv"); library("KMsurv")
if(!require("gbm")) install.packages("gbm"); library("gbm")
if(!require("xtable")) install.packages("xtable"); library("xtable")
if(!require("SurvRegCensCov")) install.packages("SurvRegCensCov"); library("SurvRegCensCov")
if(!require("survAUC")) install.packages("survAUC"); library("survAUC")

```
#1. What ist Survival Analysis?
Survival analysis encompasses a variety of techniques to predict if or when a subject under observation will experience an event (failure, death, etc.) and to find out the hazard of an event going to happen or the probability that a subject will survive.


*__Typical fields of application are:__  
*Medical studies  
*Credit risk modeling  
*Marketing  
*Failure prediction and monitoring of technical devices  

*__Predictors are domain spedific:__  
*Health data: blood sugar levels ,heart rate, eating habits  
*Customer data: income, job, family situation  
*Monitoring data: machine status, uptimes, error counts  



Parametric techniques consider predictors, non parametric techniques only look at the event/no event ratio of all subjects.

__Three Main Groups__  
```{r include = FALSE}

sagroups <-  matrix( nrow=3, ncol=3) 
sagroups <- as.data.frame(sagroups)
colnames(sagroups) <- c("Non-parametric:","Semi-parametric:","Parametric:")
sagroups[1,1] <- c("Kaplan Meyer")
sagroups[1,2] <- c("Cox Proportional Hazard")
sagroups[1,3] <- c("Accelerated Failure Time")
sagroups[2,2] <- c("Gradient Boosting with Cox")
sagroups[3,2] <- c("Gradient Boosting Machine CI")
```
```{r xtable1, results='asis'}
print(sagroups,type ="html")
```

##Dataset overview
```{r include = FALSE}
#pbc dataset
data(pbc,package = "survival")
#hdd dataset
c <- readRDS("./data_2016_rds/hdd_Dataset.rds")

cox_data <- c
cox_data$startdate <- 0
cox_data[cox_data$date ==1,]$startdate <- 0
cox_data[cox_data$date ==90,]$startdate <- 1
cox_data[cox_data$date ==180,]$startdate <-90
cox_data[cox_data$date ==270,]$startdate <- 180
cox_data[cox_data$date ==366,]$startdate <- 270


ds <-  matrix( nrow=3, ncol=6) 
ds <- as.data.frame(ds)
colnames(ds) <- c("Dataset:","Nr. Observations","Nr. Features","Time Varying Covariates","Censored","Type")
ds[1,1] <- c("HDD SMART States")
ds[1,2] <- NROW(cox_data)
ds[1,3] <- NROW(colnames(cox_data))
ds[1,4] <- c("yes")
ds[1,5] <- c("right")
ds[1,6] <- c("Technical Monitoring")

ds[2,1] <- c("pbc")
ds[2,2] <- NROW(pbc)
ds[2,3] <- NROW(colnames(pbc))
ds[2,4] <- c("no")
ds[2,5] <- c("right")
ds[2,6] <- c("Medical")

```

```{r xtable2, results = 'asis'}
print(ds,type ="html")
```
### Datasets en Detail
#### PDC Set

####Number of Items:
```{r}
print(NROW(pbc))
```

####Number of Items to fail:
```{r}
print(NROW(pbc[pbc$status ==2,]))
```

####Structure:
```{r}
print(head(pbc,10))
```
#### HDD Set
Contains hard disc failure predictors (SMART States)

#####Number of Items:
```{r}
print(NROW(unique(c$serial_number)))
```

#####Number of Items to fail:
```{r}
print(NROW(unique(c[c$failure ==1,]$serial_number)))
```

#####Structure:
```{r}
print(c[c$serial_number %in% c("MJ0351YNG9Z0XA","W300K6X5"), ])
```



#2. Survival Analysis Techniques
##2.1 Kaplan Meyer
###2.1.1. Preparations
#### Create a survival element by Surv function
#### Load the package data

```{r }
data(pbc, package="survival")
days_of_survival <- with (pbc, Surv(pbc$time, pbc$status==2))
print(days_of_survival)
```

###2.1.2. Application of KM
#### Produce and plot Kaplan-Meier estimator by survfit function
```{r}

model_fit_simple <- survfit(Surv(pbc$time, pbc$status == 2) ~ 1)
autoplot(model_fit_simple) +
    labs(x = "\n Survival Time (days) ", y = "Survival Probabilities \n",
    title = "Survival Time of \n Biliary Cirrhosis Patients \n") +
    theme(plot.title = element_text(hjust=0.5),
    axis.title.x = element_text(face = "bold", color = "#FF7A33", size = 12),
    axis.title.y = element_text(face = "bold", color = "#FF7A33", size = 12),
    legend.title = element_text(face = "bold", size = 10))
```

####Show Kaplan-Meier estimates
```{r}
print(summary(model_fit_simple))
```

####Plot differences on the different treatments
```{r}

model_fit_trt <- survfit(Surv(pbc$time, pbc$status == 2) ~ pbc$trt)
autoplot(model_fit_trt) +
    labs(x = "\n Survival Time (days) ", y = "Survival Probabilities \n",
    title = "Survival Time of \n Biliary Cirrhosis Patients \n") +
    theme(plot.title = element_text(hjust=0.5),
    axis.title.x = element_text(face = "bold", color = "#FF7A33", size = 12),
    axis.title.y = element_text(face = "bold", color = "#FF7A33", size = 12),
    legend.title = element_text(face = "bold", size = 10))

```




####Show Kaplan-Meier estimates
```{r}
print(summary(model_fit_trt))
```


####Performing the Mantel-Haenzel test 
Performing the Mantel-Haenzel test on conditional indepencence by function survdiff.  
Efficient in comparing groups that differ by categorical variables, but not continuous ones.  
The test statistic value is less than the critical value (using chi-square table) for  
degree of freedom equal to one. Hence, we can say that there is no significant difference  
between the two groups regarding the survival. We can follow that the actual treatment  
of these patients gave little impact on the survival chances.  
```{r}
survdiff(Surv(pbc$time, pbc$status==2)~pbc$trt)
```


####Plot differences on males and females and test log-rank test
```{r}
model_fit_sex <- survfit(Surv(pbc$time, pbc$status == 2) ~ pbc$sex)
autoplot(model_fit_sex) +
    labs(x = "\n Survival Time (days) ", y = "Survival Probabilities \n",
    title = "Survival Time of \n Biliary Cirrhosis Patients \n") +
    theme(plot.title = element_text(hjust=0.5),
    axis.title.x = element_text(face = "bold", color = "#FF7A33", size = 12),
    axis.title.y = element_text(face = "bold", color = "#FF7A33", size = 12),
    legend.title = element_text(face = "bold", size = 10))

survdiff(Surv(pbc$time, pbc$status==2)~pbc$sex)
```



####Plot differences on patience with hepatitis and without hepatitis and test log-rank test
```{r}
model_fit_hepato <- survfit(Surv(pbc$time, pbc$status == 2) ~ pbc$hepato)
autoplot(model_fit_hepato) +
    labs(x = "\n Survival Time (days) ", y = "Survival Probabilities \n",
    title = "Survival Time of \n Biliary Cirrhosis Patients \n") +
    theme(plot.title = element_text(hjust=0.5),
    axis.title.x = element_text(face = "bold", color = "#FF7A33", size = 12),
    axis.title.y = element_text(face = "bold", color = "#FF7A33", size = 12),
    legend.title = element_text(face = "bold", size = 10))

survdiff(Surv(pbc$time, pbc$status==2)~pbc$hepato)
```

####Using Survminer package, simple curve:
```{r}
ggsurvplot(model_fit_trt, data = pbc)
```




####Curve containing risk table:
```{r}
ggsurv <- ggsurvplot(model_fit_trt, data = pbc, title = "Survival Time of \n Biliary Cirrhosis Patients \n",
legend.title = "Treatment",
legend.labs = c("One", "Two"),
xlab = "\n Survival Time (days) ",
ylab = "Survival Probabilities \n",
risk.table = TRUE,
risk.table.title = "Risk Table",
conf.int = TRUE)
ggsurv
```





##2.2 Cox Proportional Hazard
### Formal Background

Cox PH gives us the hazard rates of all subjects under observation.
Hazard rate =  parametric part * non parametric part.
The parametric part captures the relative hazard inferred by the covariates and is not dependent on time.
The non parametric part is defined by the ratio of event / no event and is independent of the covariates.

The effect of covariates can be estimated independent of the baseline hazard by Cox proportional likelihood

See blackboard for formula!



###Preparation
#### Train and test data sets for PDC set
```{r}

pbc_clean <- pbc[!is.na(pbc$age) 
                 & !is.na(pbc$edema) 
                 & !is.na(pbc$bili) 
                 & !is.na(pbc$albumin) 
                 & !is.na(pbc$protime)
                 ,]  


#Selecting 75%  from initial population
samplepbc <- sample.int(n = NROW(pbc_clean), size = floor(.75*NROW(pbc_clean)), replace = F)
trainpbc <- pbc_clean[samplepbc,]
testpbc  <- pbc_clean[-samplepbc,]
```


#### Train and test data sets for HDD set

```{r}

trainsn <- unique(cox_data[cox_data$startdate ==0,]$serial_number)
trainsn <- trainsn[sample(NROW(trainsn))] # shuffle

#Selecting 75% of serial numbers from initial population
sample <- sample.int(n = NROW(trainsn), size = floor(.75*NROW(trainsn)), replace = F)
train <- trainsn[sample ]
test  <- trainsn[-sample ]

trainset <- cox_data[cox_data$serial_number %in% train,]
testset <- cox_data[cox_data$serial_number %in% test,]
```



### Application and code
#### Cox PH on PBC Dataset
building the cox model
```{r}
pbc.cox <- coxph(Surv(time,status ==2 ) ~age + edema +log(bili) +log(albumin)+log(protime), data = trainpbc)
print(summary(pbc.cox))

```
##### Predicting hazard ratios on testset 
relative to the sample average for all predictor variables -> these are the betas
```{r}
coxpredicted_trainpbc <- predict(pbc.cox,type="lp")  
coxpredicted_testpbc <- predict(pbc.cox, newdata=testpbc,type="lp") 

print(head(coxpredicted_testpbc,10))
```
##### Hazard for each subject 
for day 110, (basehazard*exp(lp))  
```{r}

cox_bazehaz <- basehaz(pbc.cox)
print(head(cox_bazehaz,10))
cox_predhaz_t110 <- cox_bazehaz[5,1]*coxpredicted_testpbc
print(head(cox_predhaz_t110, n=10))
```

#####Calculate Survival probabilities of subjects in testset
```{r}
Pred_Prob <- predictSurvProb(pbc.cox,newdata=testpbc,times=c(110))  
print(head(Pred_Prob, n=10))
```


#### Cox PH on HDD Dataset
#####Building the cox model
```{r}

train.cox <- coxph(Surv(startdate, date, failure) ~ smart_9_normalized + smart_5_normalized +smart_187_normalized 
                   +smart_188_normalized+smart_197_normalized + smart_198_normalized,
                   data = trainset)
print(summary(train.cox))
```

##### Predicting hazard ratios on testset 
```{r}
coxpredicted_train <- predict(train.cox,type="lp")  
coxpredicted_test <- predict(train.cox, newdata=testset,type="lp") 
#print(head(coxpredicted_test,10))
```


##2.2 Accelarated Time To Failure Model
###2.2.1 Preparation
```{r}
##First adjust data quickly
##Change status to be binary (1 alive, but liver transplantation, 0 is alive, 2 is dead)
pbc$status[which(pbc$status == 1)] <- 0
pbc$status[which(pbc$status == 2)] <- 1

##Adjust protime to account for NAs
pbc$protime[which(is.na(pbc$protime))] <- 0.1
```



###2.2.2 Building the ATF Model
```{r}
##Modelling ATF Model
atf_model_weibull <- survreg(Surv(pbc$time, pbc$status == 2) ~ pbc$age + pbc$edema + log(pbc$bili) + log(pbc$albumin) + log(pbc$protime), dist='weibull')
summary(atf_model_weibull)

atf_model_exponential <- survreg(Surv(pbc$time, pbc$status == 2) ~ pbc$age + pbc$edema + log(pbc$bili) + log(pbc$albumin) + log(pbc$protime), dist='exponential')
summary(atf_model_exponential)

atf_model_log <- survreg(Surv(pbc$time, pbc$status == 2) ~ pbc$age + pbc$edema + log(pbc$bili) + log(pbc$albumin) + log(pbc$protime), dist='loglogistic')
summary(atf_model_log)
```

```{r}



####2.2.3 Receive AUC and ROC plot for all ATF models
```{r}

par(mfrow = c(2, 2))
pred_atf <- prediction(predict(atf_model_weibull), pbc$status)
perf_atf <- performance(pred_atf,"tpr","fpr")
plot(perf_atf)
abline(a=0, b= 1)
auc.perf_atf_weibull = performance(pred_atf, measure = "auc")
auc.perf_atf_weibull@y.values

pred_exponential <- prediction(predict(atf_model_exponential), pbc$status)
perf_exponential <- performance(pred_exponential,"tpr","fpr")
plot(perf_exponential)
abline(a=0, b= 1)
auc.perf_atf_exponential = performance(pred_exponential, measure = "auc")
auc.perf_atf_exponential@y.values

pred_log <- prediction(predict(atf_model_log), pbc$status)
perf_log <- performance(pred_log,"tpr","fpr")
plot(perf_log)
abline(a=0, b= 1)
auc.perf_atf_log = performance(pred_log, measure = "auc")
auc.perf_atf_log@y.values
```


##2.3 Survival Gradient Boosting with Cox
```{r include = FALSE}

if(!require("KMsurv")) install.packages("KMsurv"); library("KMsurv")
if(!require("survAUC")) install.packages("survAUC"); library("survAUC")
if(!require("survival")) install.packages("survival"); library("survival")
```
### Formal Background
Gradient Boosting comes from the family of ensemble learning techniques.
A weak learner, in our case a decision tree, is fitted sequentially to create a stronger predictive model.
In general it tries to iteratively map y <- x*beta in such a way that a cost function is minimized. beta is the set of parameters.


See blackboard for formula.


###Application on PBC Set
#### Building the model
```{r}

gbmpbc = gbm(pbc.cox,
             data = trainpbc,
             distribution = "coxph",
             n.trees = 2500,
             shrinkage = 0.02,
             n.minobsinnode = 4)

print(summary(gbmpbc))
```
#### Predicting hazard ratios on testset 
```{r}

gbmtrainpbc = predict(object = gbmpbc,
                      newdata = trainpbc,
                      n.trees = 1500,
                      type = "response")

gbmtestpbc = predict(object = gbmpbc,
                     newdata = testpbc,
                     n.trees = 1500,
                     type = "response")
print(head(gbmtestpbc,10))

```

```{r include = FALSE}
Survresptrainpbc <- Surv(trainpbc$time,trainpbc$status==2)
Survresptestpbc <- Surv(testpbc$time,testpbc$status == 2)
CI_gbmpbc <- BeggC(Survresptrainpbc, Survresptestpbc, gbmtrainpbc, gbmtestpbc)
if(CI_gbmpbc<=0.5){
  CI_gbmpbc =1-CI_gbmpbc
}
```

### Application on HDD Set
gbm does not support intervall partitioned data. therefore  we look at the full timespan

#### Building the model
```{r}
train.coxgbm <- coxph(Surv( date, failure) ~ smart_9_normalized + smart_5_normalized +smart_187_normalized 
                      +smart_188_normalized+smart_197_normalized + smart_198_normalized,
                      data = trainset)


#we don't have startdate here
gbmhdd = gbm(train.coxgbm,
             data = trainset,
             distribution = "coxph",
             n.trees = 2500,
             shrinkage = 0.02,
             n.minobsinnode = 4)
#print(summary(gbmhdd))
```

#### Predicting hazard ratios on testset 
```{r}
gbmtrainhdd = predict(object = gbmhdd,
                      newdata = trainset,
                      n.trees = 1500,
                      type = "response")


gbmtesthdd = predict(object = gbmhdd,
                     newdata = testset,
                     n.trees = 1500,
                     type = "response")

#print(head(gbmtesthdd,10))



```

```{r include = FALSE}
Survresptrainhddgbm <- Surv(trainset$date,trainset$failure)
Survresptesthddgbm <- Surv(testset$date,testset$failure)
CI_gbmhdd <- BeggC(Survresptrainhddgbm, Survresptesthddgbm, gbmtrainhdd, gbmtesthdd)
if(CI_gbmhdd<=0.5){
  CI_gbmhdd =1-CI_gbmhdd
}
```



#3. Benchmark and Prediction 
##3.1 How to analyze and access a single subject
```{r}
## Accessing the odds of a single person/data point in the data set to predict its individual survival:
data(pbc)
pbc$protime[which(is.na(pbc$protime))] <- 0.1
cox_model <- coxph(Surv(time, status == 2) ~ age + edema + log(bili) + log(albumin) + log(protime), data=pbc)
summary(cox_model)
curves <- survfit(cox_model, pbc)
curves[10]
curves[100]
curves[200]
par(mfrow = c(2, 2))
plot(curves[10], xlab = "Days", ylab="Survival Probability")
plot(curves[100], xlab = "Days", ylab="Survival Probability")
plot(curves[200], xlab = "Days", ylab="Survival Probability")
```
```{r}
## To add entirely new data and see its performance, we have to enrich X
## curves <- survfit(cox_model, newdata = X)
plot(survfit(cox_model, newdata=data.frame(age=60,edema=2.0,bili=2.6,albumin=1.3,protime=3)),
xlab = "Days", ylab="Survival")
```
##3.2. Predicting the future outlook
The cumulative incidence curve is an alternative to the Kaplan-Meier for competing risks data.  
A Kaplan-Meier estimate, treating death due to other causes as censored, gives a 12 year cumulate rate of 10%  
for the 424 patients of PBC. The CuIn estimate, on the other hand, estimates the total number of conversions  
that will actually occur. Because the population is older, this is smaller than the KM,  
7% at 12 years for PBC's data. If there were no censoring, then CuIn(t) could very simply be computed as  
total number of patients with progression by time t divided by the sample size n.  
```{r}

par(mfrow = c(1, 1))
fitKM <- survfit(Surv(time, status==1) ~1, data=pbc)

fitCI <- survfit(Surv(time, status, type="mstate") ~1,
data=pbc)

# CI curves are always plotted from 0 upwards, rather than 1 down
plot(fitCI, xscale=365.25, xmax=7300, mark.time=FALSE,
col=2:3, xlab="Years post diagnosis of PBC")
lines(fitKM, fun='event', xmax=7300, mark.time=FALSE,
conf.int=FALSE)
text(500, .4, "Competing risk: death", col=3)
text(500, .15,"Competing risk: progression", col=2)
text(500, .30,"Kaplan Meier: prog")

```
##3.3 Benchmarking Methods
###3.3.1 ROC - Receiver operating characteristic
```{r}
## First, change status to be binary (1 alive, but liver transplantation, 0 is alive, 2 is dead)
pbc$status[which(pbc$status == 1)] <- 0
pbc$status[which(pbc$status == 2)] <- 1

## Generate predictions of cox_model and performance variable and plot the ROC
pred <- prediction(predict(cox_model), pbc$status)
perf <- performance(pred,"tpr","fpr")
plot(perf)
abline(a=0, b= 1)
```
Sensitivity: Probability that a person with the disease will have a positive test result.    
Specificity: Probability that a person without the disease will have a negative test result.  
At every cutoff, the TPR and FPR are calculated and plotted. The smoother the graph, the more cutoffs the predictions have.
We also plotted a 45-degree line, which represents, on average, the performance of a Uniform(0, 1) random variable.
The further away (towards (0,1) from the diagonal line, the better.
Overall, we see that we see gains in sensitivity (true positive rate, (> 80%)), trading off a false positive rate (1- specificity),
up until about 25% FPR. After an FPR of 25%, we don't see significant gains in TPR for a tradeoff of increased FPR.

###3.3.2 AUC - Area under the curve
```{r}
## Receive the AUC
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
```
##3.4 Benchmark the models
Training a data set
```{r}
data(pbc,package = "survival")
pbc_clean <- pbc[!is.na(pbc$age)
& !is.na(pbc$edema)
& !is.na(pbc$bili)
& !is.na(pbc$albumin)
& !is.na(pbc$protime)
& !is.na(pbc$status)
,]
```

Selecting 33%, 66% and 100%  from initial population
```{r}
samplepbc <- sample.int(n = NROW(pbc_clean), size = floor(.33*NROW(pbc_clean)), replace = F)
trainpbc_1_3 <- pbc_clean[samplepbc,]
testpbc_2_3  <- pbc_clean[-samplepbc,]
samplepbc <- sample.int(n = NROW(pbc_clean), size = floor(.66*NROW(pbc_clean)), replace = F)
trainpbc_2_3 <- pbc_clean[samplepbc,]
testpbc_1_3  <- pbc_clean[-samplepbc,]
```


Building the trained proportional hazard cox models
```{r}
pbc.cox_1_3 <- coxph(Surv(time,status ==2 ) ~age + edema +log(bili) +log(albumin)+log(protime), data = trainpbc_1_3)
pbc.cox_2_3 <- coxph(Surv(time,status ==2 ) ~age + edema +log(bili) +log(albumin)+log(protime), data = trainpbc_2_3)
pbc.cox_3_3 <- coxph(Surv(time,status ==2 ) ~age + edema +log(bili) +log(albumin)+log(protime), data = pbc_clean)

```

Building a gradient boosting model from the above mentioned cox model
```{r}
gbmpbc_1_3 = gbm(pbc.cox_1_3,
data = trainpbc_1_3,
distribution = "coxph",
n.trees = 2500,
shrinkage = 0.02,
n.minobsinnode = 4)

gbmpbc_2_3 = gbm(pbc.cox_2_3,
data = trainpbc_2_3,
distribution = "coxph",
n.trees = 2500,
shrinkage = 0.02,
n.minobsinnode = 4)

gbmpbc_3_3 = gbm(pbc.cox_3_3,
data = pbc_clean,
distribution = "coxph",
n.trees = 2500,
shrinkage = 0.02,
n.minobsinnode = 4)
```

Modelling the ATF models
```{r}

atf_model_weibull_1_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='weibull', data = trainpbc_1_3)
atf_model_weibull_2_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='weibull', data = trainpbc_2_3)
atf_model_weibull_3_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='weibull', data = pbc_clean)

atf_model_exponential_1_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='exponential', data = trainpbc_1_3)
atf_model_exponential_2_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='exponential', data = trainpbc_2_3)
atf_model_exponential_3_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='exponential', data = pbc_clean)

atf_model_log_1_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='loglogistic', data = trainpbc_1_3)
atf_model_log_2_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='loglogistic', data = trainpbc_2_3)
atf_model_log_3_3 <- survreg(Surv(time, status == 2) ~ age + edema +log(bili) +log(albumin)+log(protime), dist='loglogistic', data = pbc_clean)

```

##3.5 Receive AUCs for all models

First, generate a binary variable again
```{r}
trainpbc_1_3$status[which(trainpbc_1_3$status == 1)] <- 0
trainpbc_1_3$status[which(trainpbc_1_3$status == 2)] <- 1
trainpbc_2_3$status[which(trainpbc_2_3$status == 1)] <- 0
trainpbc_2_3$status[which(trainpbc_2_3$status == 2)] <- 1
pbc_clean$status[which(pbc_clean$status == 1)] <- 0
pbc_clean$status[which(pbc_clean$status == 2)] <- 1
```


Now generate predictions on all models
```{r}
pred_coxph_1_3 <- prediction(predict(pbc.cox_1_3), trainpbc_1_3$status)
pred_coxph_2_3 <- prediction(predict(pbc.cox_2_3), trainpbc_2_3$status)
pred_coxph_3_3 <- prediction(predict(pbc.cox_3_3), pbc_clean$status)

pred_gbmpbc_1_3 = prediction(predict(object = gbmpbc_1_3,
newdata = trainpbc_1_3,
n.trees = 1500,
type = "response"), trainpbc_1_3$status)
pred_gbmpbc_2_3 = prediction(predict(object = gbmpbc_2_3,
newdata = trainpbc_2_3,
n.trees = 1500,
type = "response"), trainpbc_2_3$status)
pred_gbmpbc_3_3 = prediction(predict(object = gbmpbc_3_3,
newdata = pbc_clean,
n.trees = 1500,
type = "response"), pbc_clean$status)

pred_atf_model_weibull_1_3 <- prediction(predict(atf_model_weibull_1_3), trainpbc_1_3$status)
pred_atf_model_weibull_2_3 <- prediction(predict(atf_model_weibull_2_3), trainpbc_2_3$status)
pred_atf_model_weibull_3_3 <- prediction(predict(atf_model_weibull_3_3), pbc_clean$status)

pred_atf_model_exponential_1_3 <- prediction(predict(atf_model_exponential_1_3), trainpbc_1_3$status)
pred_atf_model_exponential_2_3 <- prediction(predict(atf_model_exponential_2_3), trainpbc_2_3$status)
pred_atf_model_exponential_3_3 <- prediction(predict(atf_model_exponential_3_3), pbc_clean$status)

pred_atf_model_log_1_3 <- prediction(predict(atf_model_log_1_3), trainpbc_1_3$status)
pred_atf_model_log_2_3 <- prediction(predict(atf_model_log_2_3), trainpbc_2_3$status)
pred_atf_model_log_3_3 <- prediction(predict(atf_model_log_3_3), pbc_clean$status)
```


Now receive the AUC values for each model
```{r}
auc.perf_coxph_1_3 = performance(pred_coxph_1_3, measure = "auc")
auc.perf_coxph_2_3 = performance(pred_coxph_2_3, measure = "auc")
auc.perf_coxph_3_3 = performance(pred_coxph_3_3, measure = "auc")

auc.perf_gbmpbc_1_3 = performance(pred_gbmpbc_1_3, measure = "auc")
auc.perf_gbmpbc_2_3 = performance(pred_gbmpbc_2_3, measure = "auc")
auc.perf_gbmpbc_3_3 = performance(pred_gbmpbc_3_3, measure = "auc")

auc.perf_atf_model_weibull_1_3 = performance(pred_atf_model_weibull_1_3, measure = "auc")
auc.perf_atf_model_weibull_2_3 = performance(pred_atf_model_weibull_2_3, measure = "auc")
auc.perf_atf_model_weibull_3_3 = performance(pred_atf_model_weibull_3_3, measure = "auc")

auc.perf_atf_model_exponential_1_3 = performance(pred_atf_model_exponential_1_3, measure = "auc")
auc.perf_atf_model_exponential_2_3 = performance(pred_atf_model_exponential_2_3, measure = "auc")
auc.perf_atf_model_exponential_3_3 = performance(pred_atf_model_exponential_3_3, measure = "auc")

auc.perf_atf_model_log_1_3 = performance(pred_atf_model_log_1_3, measure = "auc")
auc.perf_atf_model_log_2_3 = performance(pred_atf_model_log_2_3, measure = "auc")
auc.perf_atf_model_log_3_3 = performance(pred_atf_model_log_3_3, measure = "auc")

```

##3.7 Concordance Index
The output of the cox function are relative hazards.
Lower hazard in general means longer survival time and vice versa.
Therefore Cox implicitly ranks subjects by hazard (thus by survival time).
The goodness of ranking can me measured by CI.

CI is the fraction of correctly ordered pairs of subjects compared to all pairs of subjects that can be ordered
(Every pair that includes at least one actual failure)

For formula see blackboard.

### CI for COX PH HDD Set

Calculating Concordance Index to assess results of prediction
```{r}
# creating survival objects as response variables
Survresptrain <- Surv(trainset$startdate,trainset$date, trainset$failure  ) 
Survresptest <- Surv(testset$startdate,testset$date, testset$failure)     
# we don't need baseline hazards to measure the ranking since every item is affected by the bh in the same ways
 # only the relative hazard is of interest here                                                                         


CI_cox <- BeggC(Survresptrain, Survresptest, coxpredicted_train, coxpredicted_test)
if(CI_cox<=0.5){
  CI_cox =1-CI_cox
}
```
### CI overview


```{r}
resultsdf <-  matrix( nrow=2, ncol=2) 
resultsdf <- as.data.frame(resultsdf)
colnames(resultsdf) <- c("PBC-Set","HDD-Set")
rownames(resultsdf) <- c("CoxPH","GBMCox")

resultsdf[1,1] <- CI_coxpbc
resultsdf[1,2] <- CI_cox
resultsdf[2,1] <- CI_gbmpbc
resultsdf[2,2] <- paste(CI_gbmhdd," not comparable; no tv covars!")




```
CI Could also be used to learn a GBM Model (GBMCI)
Model tries to rank subjects by survival times so that CI becomes optimal


#4. Conclusion and Outlook
Table AUC and CI for all models
```{r}
table_benchmark <- read.csv("benchmark.csv", fill = TRUE, header = TRUE, sep = ";")
print(table_benchmark)
```

##3.6 Final Benchmarking and Future Outlook
It can happen that we have different costs for false negative and false positive
The output from opt.cut and a performance object with measure cost are NOT equivalent if false positives and false negatives
are not weighted equally. The cost.fn and cost.fp arguments can be passed to performance, corresponding to the cost of a false negative and false positive, respectively (This is minimize cost criterion).

```{r}
cost.perf = performance(pred, "cost", cost.fp = 2, cost.fn = 1)
pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
```

Plotting the cost line, once weighted and once by the ROCR standard cost.
```{r}
plot(performance(pred,"cost"))
plot(cost.perf)

```
If we want to only accept a for of x percentage points, like 0.1 as false correct prediction, we need to first
define a function pROC and then plot the graph.
As result, if we can only accept a FPR of 10%, the model is only giving 50% sensitivity (TPR) at 10% FPR (1-specificity).
```{r}
pROC = function(pred, fpr.stop){
    perf <- performance(pred,"tpr","fpr")
    for (iperf in seq_along(perf@x.values)){
        ind = which(perf@x.values[[iperf]] <= fpr.stop)
        perf@y.values[[iperf]] = perf@y.values[[iperf]][ind]
        perf@x.values[[iperf]] = perf@x.values[[iperf]][ind]
    }
    return(perf)
}
```
Plotting the new line
```{r}

proc.perf = pROC(pred, fpr.stop=0.1)
plot(proc.perf)
abline(a=0, b= 1)
```

Address now for evaluation the partial AUC, this value can range from 0 to infinity
```{r}
pauc.perf = performance(pred, measure = "auc", fpr.stop=0.1)
pauc.perf@y.values
```

Divide pAUC by fpr.stop to receive a standardized result form 0 to 1 like AUC
```{r}
pauc.perf@y.values = lapply(pauc.perf@y.values, function(x) x / 0.1)
pauc.perf@y.values
```



Backup - FOR Concordance Indices
```{r}
## gbmpbc_1_3
gbmtrainpbc = predict(object = gbmpbc_1_3,
newdata = trainpbc_1_3,
n.trees = 1500,
type = "response")


gbmtestpbc = predict(object = gbmpbc_1_3,
newdata = testpbc_2_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_1_3$time,trainpbc_1_3$status==2)
Survresptestpbc <- Surv(testpbc_2_3$time,testpbc_2_3$status == 2)
CI_gbmpbc_1_3 <- BeggC(Survresptrainpbc, Survresptestpbc, gbmtrainpbc, gbmtestpbc)
if(CI_gbmpbc_1_3<=0.5){
    CI_gbmpbc_1_3 =1-CI_gbmpbc_1_3
}
CI_gbmpbc_1_3

## gbmpbc_2_3
gbmtrainpbc = predict(object = gbmpbc_2_3,
newdata = trainpbc_2_3,
n.trees = 1500,
type = "response")


gbmtestpbc = predict(object = gbmpbc_2_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_2_3$time,trainpbc_2_3$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_gbmpbc_2_3 <- BeggC(Survresptrainpbc, Survresptestpbc, gbmtrainpbc, gbmtestpbc)
if(CI_gbmpbc_2_3<=0.5){
    CI_gbmpbc_2_3 =1-CI_gbmpbc_2_3
}
CI_gbmpbc_2_3

## atf_model_weibull_1_3
trainpbc = predict(object = atf_model_weibull_1_3,
newdata = trainpbc_1_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_weibull_1_3,
newdata = testpbc_2_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_1_3$time,trainpbc_1_3$status==2)
Survresptestpbc <- Surv(testpbc_2_3$time,testpbc_2_3$status == 2)
CI_atf_model_weibull_1_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_weibull_1_3<=0.5){
    CI_atf_model_weibull_1_3 =1-CI_atf_model_weibull_1_3
}
CI_atf_model_weibull_1_3

## atf_model_weibull_2_3
trainpbc = predict(object = atf_model_weibull_2_3,
newdata = trainpbc_2_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_weibull_2_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_2_3$time,trainpbc_2_3$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_weibull_2_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_weibull_2_3<=0.5){
    CI_atf_model_weibull_2_3 =1-CI_atf_model_weibull_2_3
}
CI_atf_model_weibull_2_3

## atf_model_weibull_3_3
trainpbc = predict(object = atf_model_weibull_3_3,
newdata = pbc_clean,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_weibull_3_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(pbc_clean$time,pbc_clean$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_weibull_3_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_weibull_3_3<=0.5){
    CI_atf_model_weibull_3_3 =1-CI_atf_model_weibull_3_3
}
CI_atf_model_weibull_3_3

## atf_model_exponential_1_3
trainpbc = predict(object = atf_model_exponential_1_3,
newdata = trainpbc_1_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_exponential_1_3,
newdata = testpbc_2_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_1_3$time,trainpbc_1_3$status==2)
Survresptestpbc <- Surv(testpbc_2_3$time,testpbc_2_3$status == 2)
CI_atf_model_exponential_1_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_exponential_1_3<=0.5){
    CI_atf_model_exponential_1_3 =1-CI_atf_model_exponential_1_3
}
CI_atf_model_exponential_1_3

## atf_model_exponential_2_3
trainpbc = predict(object = atf_model_exponential_2_3,
newdata = trainpbc_2_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_exponential_2_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_2_3$time,trainpbc_2_3$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_exponential_2_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_exponential_2_3<=0.5){
    CI_atf_model_exponential_2_3 =1-CI_atf_model_exponential_2_3
}
CI_atf_model_exponential_2_3

## atf_model_exponential_3_3
trainpbc = predict(object = atf_model_exponential_3_3,
newdata = pbc_clean,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_exponential_3_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(pbc_clean$time,pbc_clean$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_exponential_3_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_exponential_3_3<=0.5){
    CI_atf_model_exponential_3_3 =1-CI_atf_model_exponential_3_3
}
CI_atf_model_exponential_3_3

## atf_model_log_1_3
trainpbc = predict(object = atf_model_log_1_3,
newdata = trainpbc_1_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_log_1_3,
newdata = testpbc_2_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_1_3$time,trainpbc_1_3$status==2)
Survresptestpbc <- Surv(testpbc_2_3$time,testpbc_2_3$status == 2)
CI_atf_model_log_1_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_log_1_3<=0.5){
    CI_atf_model_log_1_3 =1-CI_atf_model_log_1_3
}
CI_atf_model_log_1_3

## atf_model_log_2_3
trainpbc = predict(object = atf_model_log_2_3,
newdata = trainpbc_2_3,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_log_2_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(trainpbc_2_3$time,trainpbc_2_3$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_log_2_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_log_2_3<=0.5){
    CI_atf_model_log_2_3 =1-CI_atf_model_log_2_3
}
CI_atf_model_log_2_3

## atf_model_log_3_3
trainpbc = predict(object = atf_model_log_3_3,
newdata = pbc_clean,
n.trees = 1500,
type = "response")


testpbc = predict(object = atf_model_log_3_3,
newdata = testpbc_1_3,
n.trees = 1500,
type = "response")


Survresptrainpbc <- Surv(pbc_clean$time,pbc_clean$status==2)
Survresptestpbc <- Surv(testpbc_1_3$time,testpbc_1_3$status == 2)
CI_atf_model_log_3_3 <- BeggC(Survresptrainpbc, Survresptestpbc, trainpbc, testpbc)
if(CI_atf_model_log_3_3<=0.5){
    CI_atf_model_log_3_3 =1-CI_atf_model_log_3_3
}
CI_atf_model_log_3_3
```
